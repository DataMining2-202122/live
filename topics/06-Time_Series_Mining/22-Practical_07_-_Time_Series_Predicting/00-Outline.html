<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Data Mining 2</title>

    <!-- Bootstrap core CSS -->
    <link href="../../../style/bootstrap/css/bootstrap.min.css" rel="stylesheet">
<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="../../../style/codehilite/css/default.css" rel="stylesheet">
    <link href="../../../style/misc/css/module.css" rel="stylesheet">
    <link href="../../../style/misc/css/practical.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

	<script type="text/javascript"
	  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>

  </head>

<body>

	<!-- Fixed navbar -->
	<div class="navbar navbar-default navbar-fixed-top" role="navigation">
		<div class="container">
			
			
	    	<div class="collapse navbar-collapse">

				<ul class="nav navbar-nav navbar-left">
					<!-- Moodle -->
					<li>
						<div class="navbar-header">
							<a class="navbar-brand" href="https://moodle.wit.ie/course/view.php?id=182862" target="_blank"><img height="18pt" src="../../../style/misc/img/moodle_logo_on_blue.gif" /></a>
						</div>						
					</li>
					<li>
						<div class="navbar-header">
							<a class="navbar-brand" href="https://moodle.wit.ie/course/view.php?id=182862" target="_blank"><img height="18pt" src="../../../style/misc/img/slack_logo.png" /></a>
						</div>						
					</li>
				</ul>

	      		<ul class="nav navbar-nav navbar-right">

					<!-- module home -->
					<li>
						<div class="navbar-header">
							<a class="navbar-brand" href="../../../index.html"><span class="glyphicon glyphicon-home"></span></a>
						</div>						
					</li>
					
					<!-- topics -->
	        		<li>
						<div class="navbar-collapse collapse" id="b">
							<ul class="nav navbar-nav">
								<li class="dropdown">
									<a href="#" class="dropdown-toggle" data-toggle="dropdown">
										<span class="glyphicon glyphicon-list-alt"></span>
									</a>
									<ul class="dropdown-menu" role="menu">
										<li class="dropdown-header">Topics</li>
										
										<li >
											<a href="../../../topics/01-Module_Introduction/index.html">Module Introduction</a>
										</li>
										
										<li >
											<a href="../../../topics/02-Feature_Engineering/index.html">Feature Engineering</a>
										</li>
										
										<li >
											<a href="../../../topics/03-Review_of_Model_Building/index.html">Review of Model Building</a>
										</li>
										
										<li >
											<a href="../../../topics/04-Hyperparameter_Tuning/index.html">Hyperparameter Tuning</a>
										</li>
										
										<li >
											<a href="../../../topics/05-Ensemble_Learning/index.html">Ensemble Learning</a>
										</li>
										
										<li class="active">
											<a href="../../../topics/06-Time_Series_Mining/index.html">Time Series Mining</a>
										</li>
										
										<li >
											<a href="../../../topics/07-Text_Mining/index.html">Text Mining</a>
										</li>
										
										<li >
											<a href="../../../topics/21-Assignments/index.html">Assignments</a>
										</li>
										
									</ul>
								</li>
							</ul>
						</div>			
					</li>

					<!-- resources -->
	        		<li>
						<div class="navbar-collapse collapse" id="b">
							<ul class="nav navbar-nav">
								<li class="dropdown">
									<a href="#" class="dropdown-toggle" data-toggle="dropdown">
										<span class="glyphicon glyphicon-th-list"></span>
									</a>
									<ul class="dropdown-menu" role="menu">
										<li class="dropdown-header">Resources</li>
										
										<li >
											<a href="../../../topics/06-Time_Series_Mining/index.html#01-Introduction_to_Time_Series_Mining">Introduction to Time Series Mining</a>
										</li>
										
										<li >
											<a href="../../../topics/06-Time_Series_Mining/index.html#21-Practical_06_-_Time_Series_Mining">Practical 06 - Time Series Mining</a>
										</li>
										
										<li class="active">
											<a href="../../../topics/06-Time_Series_Mining/index.html#22-Practical_07_-_Time_Series_Predicting">Practical 07 - Time Series Predicting</a>
										</li>
										
									</ul>
								</li>
							</ul>
						</div>			
					</li>
								
					<!-- pages-->
	        		<li>
						<div class="navbar-collapse collapse" id="c">
							<ul class="nav navbar-nav">
								<li class="dropdown">
									<a href="#" class="dropdown-toggle" data-toggle="dropdown">
										<span>Outline</span
									</a>
									<ul class="dropdown-menu" role="menu">
										
										<li class="active">
											<a href="00-Outline.html">Outline</a>
										</li>
										
									</ul>
								</li>
							</ul>
						</div>			
					</li> 
					
	        	</ul>
			</div>
		</div>
	</div>

	<!-- contents -->
	<div class="container">
		
		<ul class="pager">
			
			<li class="previous disabled"><a>&larr; Previous</a></li>
			
			
			
			<li class="next disabled"><a>Next &rarr;</a></li>
			
		</ul>
		
		<h1>Time Series Predictions - Comparing ARIMA and LSTM models</h1>
<h2>Outline</h2>
<p>In last week's practical we focused on constructing (classical) time series models. This week we will look at generating predictions, and also compare (classical) ARIMA models to modern LSTM models</p>
<h2>Imports and Setup</h2>
<p>Create a notebook with standard imports</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">import</span> <span class="nn">warnings</span> 
<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">statsmodels.tsa.arima.model</span> <span class="kn">import</span> <span class="n">ARIMA</span>

<span class="kn">import</span> <span class="nn">datetime</span> <span class="k">as</span> <span class="nn">dt</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;orig&#39;</span><span class="p">,</span><span class="s1">&#39;data&#39;</span><span class="p">,</span><span class="s1">&#39;output&#39;</span><span class="p">]:</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<h2>Dataset</h2>
<p>This week's datasets are stock prices. 
We will use <a href="https://nsepy.xyz">nsepy</a> API to access stock prices, which can be installed using <code>pip</code>. 
This API is relatively simple to use. For example, getting the stock for the State Bank of India (SBIN) from 1 January 2013 up to 31 December 2019 we use</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">nsepy</span> <span class="kn">import</span> <span class="n">get_history</span> <span class="k">as</span> <span class="n">gh</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2013</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2019</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">31</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">gh</span><span class="p">(</span><span class="n">symbol</span><span class="o">=</span><span class="s1">&#39;SBIN&#39;</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">end</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<p>which produced the following dataframe  </p>
<figure>
<img src="files/SBIN.png" width="80%">
<figcaption>Dataframe returned by nsepy.get_history function.</figcaption>
</figure>

<p>To keep things simple we will focus on the <code>Close</code> price</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>data = df.Close.values
</code></pre></div>
</td></tr></table>
<p>First thing we should do is generate a time plot to see if there are any issues ... using </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Time plot of Close price&quot;</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<p>we get the following</p>
<figure>
<img src="files/timeplot_raw.png" width="80%">
<figcaption>Time plot of Close price.</figcaption>
</figure>

<p>We have a large shock around data point 470. For the moment let us ignore this and see what happens.</p>
<p>If we generate the autocorrelation plot of the raw data and of the differenced data using code based on </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">pandas.plotting</span> <span class="kn">import</span> <span class="n">autocorrelation_plot</span>
<span class="n">autocorrelation_plot</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Autocorrelation plot of raw data&quot;</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<p>and <code>differenced_data=np.diff(data)</code> we get the following </p>
<figure>
<img src="files/autocorrelation_raw.png" width="40%">
<img src="files/autocorrelation_diff.png" width="40%">

<figcaption>Autocorrelation plot of raw and differenced data, showing that our ARIMA should have parameter d=1.</figcaption>
</figure>

<p>Using our parameter search code from last week we can locate the optimal model </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">itertools</span> <span class="k">as</span> <span class="nn">it</span>

<span class="n">opt_param</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">opt_aic</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">max</span>

<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">it</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)):</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">param</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">ARIMA</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">param</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">aic</span> <span class="o">&lt;</span> <span class="n">opt_aic</span><span class="p">:</span>
            <span class="n">opt_aic</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">aic</span>
            <span class="n">opt_param</span> <span class="o">=</span> <span class="n">param</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">param</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">aic</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="vm">__class__</span><span class="p">,</span> <span class="s2">&quot; occurred.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimum model is </span><span class="si">{</span><span class="n">opt_param</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<p>Which suggests that the optimal model is </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>    Optimum model is (0, 2, 1)
</code></pre></div>
</td></tr></table>
<p>Was the model fitting affected by the large shock around 470?  To check replace <code>data</code> by <code>data[500:]</code> and rerun. You should get </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>Optimum model is (2, 1, 2)
</code></pre></div>
</td></tr></table>
<p>indicating that the shock had an impact and so we should not include it in our data when training.</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">500</span><span class="p">:]</span>
</code></pre></div>
</td></tr></table>
<h2>ARIMA Models and predicting</h2>
<p>Running a ARIMA parameter search over the reduced time series suggests an
<code>ARIMA(2,1,2)</code> model.</p>
<p>We want to generate and evaluate one step ahead predictions, i.e., using known values predict the next observation, compare with actual, and repeat process at next time point, etc.</p>
<p>First we implement function </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">forecastARIMA</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">param</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="s2">&quot;Generate prediction of ARIMA(param) model at `step` steps ahead&quot;</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">ARIMA</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">param</span><span class="p">)</span>
    <span class="n">model_fit</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">model_fit</span><span class="o">.</span><span class="n">forecast</span><span class="p">()[</span><span class="n">step</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">prediction</span>
</code></pre></div>
</td></tr></table>
<p>Now let us generate the predictions for the last $T=150$ data points</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">T</span> <span class="o">=</span> <span class="mi">150</span>

<span class="n">predictions_ARIMA</span> <span class="o">=</span> <span class="p">[</span><span class="n">forecastARIMA</span><span class="p">(</span><span class="n">data</span><span class="p">[:</span><span class="n">t</span><span class="p">],</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="n">T</span><span class="p">,</span><span class="mi">0</span><span class="p">)]</span>
</code></pre></div>
</td></tr></table>
<p>And produce the following graph (code no given - this is you job)</p>
<figure>
<img src="files/ARIMA_2_1_2__predictions.png" width="80%">
<figcaption>ARIMA(2,1,2) one step ahead prediction.</figcaption>
</figure>

<p>This look good. The quality of the forecasts can be measured using standard regression metrics, so run </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">mean_squared_log_error</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The mean squared error (MSE) = &quot;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="o">-</span><span class="n">T</span><span class="p">:],</span> <span class="n">predictions_ARIMA</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The mean absolute error (MAS) = &quot;</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="o">-</span><span class="n">T</span><span class="p">:],</span> <span class="n">predictions_ARIMA</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The mean squared log error (MSLE) = &quot;</span><span class="p">,</span> <span class="n">mean_squared_log_error</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="o">-</span><span class="n">T</span><span class="p">:],</span> <span class="n">predictions_ARIMA</span><span class="p">))</span>
</code></pre></div>
</td></tr></table>
<p>to get </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>The mean squared error (MSE) =  54.138455248298285
The mean absolute error (MAS) =  5.464863023587544
The mean squared log error (MSLE) =  0.0005840156677177781
</code></pre></div>
</td></tr></table>
<p>Next we will compare this with LSTM models.</p>
<h2>LSTM Models and predicting</h2>
<p>LSTM (long short term memory) is a class of recurrent neural networks. LSTM is much more powerful and tends to work better given sufficient amounts of data. We will use a <code>tensorflow/keras</code> so before you start you will need to install <code>tensorflow</code> and <code>keras</code> using <code>conda</code>.</p>
<p>Our first step is to scale that data. We normally use <code>StandardScaler</code> which scales based on the standard deviation. Here we wil use <code>MinMaxScaler</code>, which is more commonly used with stock prices.</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">data_scaled</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">data_scaled</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>
</td></tr></table>
<p>Now we have to create the dataset with, say <code>T_TRAIN=60</code> time steps and 1 output. 
To do so, we will  use a for loop. 2575 is the length of the dataset. We hve finally creaated an array with all the values in the following step.</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">T_TRAIN</span> <span class="o">=</span> <span class="mi">60</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T_TRAIN</span><span class="p">,</span> <span class="n">data_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">X_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data_scaled</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="n">T_TRAIN</span><span class="p">:</span><span class="n">t</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">y_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data_scaled</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>
</td></tr></table>
<p>Next we reshape <code>X_train</code> dataset, to be suitable for input into the LSTM model, by converting it to a single 3D table of values.</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>
</td></tr></table>
<p>Keras is a python, neural network library which simplifies the building of neural networks in tensorflow/CNTK/Theano.</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">LSTM</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dropout</span>
</code></pre></div>
</td></tr></table>
<h3>Build the neural network</h3>
<p>Now we start to build our network ... one layer at a time ...</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">regressor</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
</code></pre></div>
</td></tr></table>
<p>Add the first layer, the input layer:</p>
<ul>
<li>Parameter <code>return_sequences</code> ensures that the layer will return its output back into the network. This helps the RNN to build a memory for itself.</li>
<li>Parameter <code>input_shape</code> should match the shape of the training data.</li>
<li>Parameter <code>units</code> represents  the dimensionality of the output space. It refers to the output of the hidden space.</li>
<li>Dropout is a regularization technique to reduces over-fitting in the neural network. </li>
</ul>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">regressor</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)))</span>
<span class="n">regressor</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
</code></pre></div>
</td></tr></table>
<p>Adding second layer ...</p>
<p>The following layers will have the same configuration as the first layer with the only difference being that in these layers we do not have to mention the input shape. </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">regressor</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="n">regressor</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
</code></pre></div>
</td></tr></table>
<p>Adding third layer ...</p>
<p>ditto</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">regressor</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="n">regressor</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
</code></pre></div>
</td></tr></table>
<p>Adding forth layer ... (no memory feedback)</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">regressor</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">units</span> <span class="o">=</span> <span class="mi">50</span><span class="p">))</span>
<span class="n">regressor</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
</code></pre></div>
</td></tr></table>
<p>Adding output Layer ...</p>
<p>The output layer is a dense layer (i.e. fully connected). 
The output of LSTM is not a <code>softmax</code>. Instead, we just get the internal state as the output. The dimensionality of the output is equal to the number of units which is mostly not the dimensionality that is desired. Therefore, a dense layer is added to solve this problem.</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">regressor</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div>
</td></tr></table>
<h3>Compiling the RNN</h3>
<p>Perhaps the most important term to be noted while comparing the RNN is the optimizer.</p>
<p>When we train the algorithm, the derivatives involved in the algorithm can becomes very big (exploding gradient) or very small(vanishing gradient). To avoid this issue, we need to optimize the algorithm. It is done by weight initialization to the deep network. Now, there are several optimizers available. However, the most efficient is the adam optimizer. Adma stands for adaptive moment estimation.</p>
<p>More detail about the <a href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/#:~:text=Adam%20is%20an%20optimization%20algorithm,iterative%20based%20in%20training%20data.&amp;text=The%20algorithm%20is%20called%20Adam">adam optimizer</a>.</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">regressor</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mean_squared_error&#39;</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<h3>Fitting RNN to the training set</h3>
<p>We now, fit the RNN to the training set. </p>
<p>Training is measured in terms of epochs and batch_size:</p>
<ul>
<li>Batch size is the number of data points into which the data is split without repetition. These batches will run through the network, forward and backward. </li>
<li>The number of times the entire data set is used is called the epochs. Here, we have put the epoch value as 100. </li>
</ul>
<p>The more the number of epochs you choose, the longer this takes to run. </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<p>Now that we have trained our model, it is time for us to check how it performs on the test set. </p>
<p>We define a one step ahead forecasting function ...</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">forecastLSTM</span><span class="p">(</span><span class="n">X_test</span><span class="p">):</span>
    <span class="s2">&quot;Generate prediction of LSTM model at `step` steps ahead&quot;</span>

    <span class="k">global</span> <span class="n">ss</span><span class="p">,</span> <span class="n">regressor</span>

    <span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
    <span class="c1"># print(X_test.shape)</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">sc</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">prediction</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>

<span class="n">forecastLSTM</span><span class="p">(</span><span class="n">data_scaled</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">T_TRAIN</span><span class="o">+</span><span class="n">T</span><span class="p">):</span><span class="o">-</span><span class="n">T</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<p>... then generate the forecasts ...</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">predictions_LSTM</span> <span class="o">=</span> <span class="p">[</span> <span class="n">forecastLSTM</span><span class="p">(</span><span class="n">data_scaled</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">T_TRAIN</span><span class="o">-</span><span class="n">t</span><span class="p">):</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="n">T</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="p">]</span>
</code></pre></div>
</td></tr></table>
<p>And produce the following graph (code no given - this is you job)</p>
<figure>
<img src="files/LSTM_predictions.png" width="80%">
<figcaption>LSTM one step ahead prediction.</figcaption>
</figure>

<p>This does not look as good as ARIMA(2,1,2) (but I cheated at stopped the training early). The quality of the forecasts can be measured using standard regression metrics, so run </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">mean_squared_log_error</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The mean squared error (MSE) = &quot;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="o">-</span><span class="n">T</span><span class="p">:],</span> <span class="n">predictions_LSTM</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The mean absolute error (MAS) = &quot;</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="o">-</span><span class="n">T</span><span class="p">:],</span> <span class="n">predictions_LSTM</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The mean squared log error (MSLE) = &quot;</span><span class="p">,</span> <span class="n">mean_squared_log_error</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="o">-</span><span class="n">T</span><span class="p">:],</span> <span class="n">predictions_LSTM</span><span class="p">))</span>
</code></pre></div>
</td></tr></table>
<p>which generates </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>The mean squared error (MSE) =  389.72153467419236
The mean absolute error (MAS) =  16.333763326009116
The mean squared log error (MSLE) =  0.004011310536499139
</code></pre></div>
</td></tr></table>
<p>This is clearly not as good a ARIMA. Can it be improved? </p>
<ul>
<li>Use a longer training interval <code>T_TRAIN</code> than I used.</li>
<li>Increase the number of epochs.</li>
<li>Insert another LSTM layer</li>
</ul>
<p>Also, what happens for other stocks?</p>
		
		<ul class="pager">
			
			<li class="previous disabled"><a>&larr; Previous</a></li>
			
			
			
			<li class="next disabled"><a>Next &rarr;</a></li>
			
		</ul>

	</div>
	
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
    <script src="../../../style/bootstrap/js/bootstrap.min.js"></script>
	
  </body>
</html>